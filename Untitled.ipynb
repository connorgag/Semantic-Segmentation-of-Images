{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60a5e53-9e4c-424a-b702-d2f54e7e36c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for train data. Found 1464 images.\n",
      "Processing data for val data. Found 2913 images.\n"
     ]
    }
   ],
   "source": [
    "from basic_fcn import FCN\n",
    "from resnet_fcn import ResNet\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import voc\n",
    "import torchvision.transforms as standard_transforms\n",
    "import util\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from util import iou, pixel_acc, plot_losses\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.normal_(m.bias.data) #xavier not applicable for biases\n",
    "\n",
    "\n",
    "\n",
    "#TODO Get class weights\n",
    "def getClassWeights():\n",
    "    # TODO for Q4.c || Caculate the weights for the classes\n",
    "    raise NotImplementedError\n",
    "\n",
    "# normalize using imagenet averages\n",
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "\n",
    "input_transform = standard_transforms.Compose([\n",
    "    standard_transforms.ToTensor(),\n",
    "    standard_transforms.Normalize(*mean_std)\n",
    "])\n",
    "augmentations = [('crop', .3), ('horizontal_flip', .3)]\n",
    "# augmentations = None\n",
    "\n",
    "target_transform = MaskToTensor()\n",
    "\n",
    "train_dataset = voc.VOC('train', transform=input_transform, target_transform=target_transform, augmentations=augmentations)\n",
    "val_dataset = voc.VOC('val', transform=input_transform, target_transform=target_transform, augmentations=augmentations)\n",
    "# test_dataset = voc.VOC('test', transform=input_transform, target_transform=target_transform)\n",
    "\n",
    "val_dataset,test_dataset = torch.utils.data.random_split(val_dataset,[0.5,0.5])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 32, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 32, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 32, shuffle=False, num_workers=num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a49ea1b-3aee-4026-ba34-ac5a82a42dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "n_class = 21\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "early_stop = True\n",
    "early_stop_epoch = 5\n",
    "from unet import unet\n",
    "fcn_model = unet(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=learning_rate)\n",
    "# scheduler = CosineAnnealingWarmRestarts(\n",
    "#             optimizer, \n",
    "#             T_0=5,      \n",
    "#             T_mult=2,\n",
    "#             eta_min=1e-6  \n",
    "#         )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fcn_model = fcn_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ee098-fb53-4070-a71b-85a4c89f3404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training: \n",
      "Initial Loss: 4.4391415948453155\n",
      "Initial IoU 0.0009086789255832173\n",
      "Initial Pixel Accuracy 0.016167088336147897\n",
      "\n",
      " Starting training.\n",
      "epoch 0:\n",
      "    iteration 0, loss: 4.547213554382324\n",
      "    iteration 20, loss: 1.4388717412948608\n",
      "    iteration 40, loss: 1.2168474197387695\n",
      "Finished epoch 0, time elapsed 34 seconds\n",
      "Loss at epoch 0: 1.2658119253490283\n",
      "IoU at epoch 0: 0.04098744625630586\n",
      "Pixel Accuracy at epoch 0: 0.7516279712967251\n",
      "\n",
      "\n",
      "epoch 1:\n",
      "    iteration 0, loss: 1.432655692100525\n",
      "    iteration 20, loss: 1.1514294147491455\n",
      "    iteration 40, loss: 1.4356601238250732\n",
      "Finished epoch 1, time elapsed 34 seconds\n",
      "Loss at epoch 1: 1.2360292388045269\n",
      "IoU at epoch 1: 0.04163328517714272\n",
      "Pixel Accuracy at epoch 1: 0.7516338656777921\n",
      "\n",
      "\n",
      "epoch 2:\n",
      "    iteration 0, loss: 1.7100956439971924\n",
      "    iteration 20, loss: 1.2056540250778198\n",
      "    iteration 40, loss: 1.2681689262390137\n",
      "Finished epoch 2, time elapsed 34 seconds\n",
      "Loss at epoch 2: 1.1816543677578801\n",
      "IoU at epoch 2: 0.04163328517714272\n",
      "Pixel Accuracy at epoch 2: 0.7516338656777921\n",
      "\n",
      "\n",
      "epoch 3:\n",
      "    iteration 0, loss: 1.2914531230926514\n",
      "    iteration 20, loss: 0.993333637714386\n",
      "    iteration 40, loss: 1.2063325643539429\n",
      "Finished epoch 3, time elapsed 34 seconds\n",
      "Loss at epoch 3: 1.1980356263077778\n",
      "IoU at epoch 3: 0.04163328517714272\n",
      "Pixel Accuracy at epoch 3: 0.7516338656777921\n",
      "\n",
      "\n",
      "epoch 4:\n",
      "    iteration 0, loss: 1.1282143592834473\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "def train():\n",
    "    \"\"\"\n",
    "    Train a deep learning model using mini-batches.\n",
    "\n",
    "    - Perform forward propagation in each epoch.\n",
    "    - Compute loss and conduct backpropagation.\n",
    "    - Update model weights.\n",
    "    - Evaluate model on validation set for mIoU score.\n",
    "    - Save model state if mIoU score improves.\n",
    "    - Implement early stopping if necessary.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    best_iou_score = 0.0\n",
    "    patience = 0\n",
    "\n",
    "    training_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        print(f\"epoch {epoch}:\")\n",
    "        epoch_losses = []\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            # TODO  reset optimizer gradients\n",
    "\n",
    "            # both inputs and labels have to reside in the same device as the model's\n",
    "            inputs =  inputs.to(device)# TODO transfer the input to the same device as the model's\n",
    "            labels =  labels.to(device) # TODO transfer the labels to the same device as the model's\n",
    "\n",
    "            outputs =  fcn_model(inputs) # TODO  Compute outputs. we will not need to transfer the output, it will be automatically in the same device as the model's!\n",
    "\n",
    "            loss =  criterion(outputs, labels.long())\n",
    "            epoch_losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "\n",
    "            if iter % 20 == 0:\n",
    "                print(\"    iteration {}, loss: {}\".format(iter, loss.item()))\n",
    "        \n",
    "        training_loss.append(np.mean(epoch_losses))\n",
    "\n",
    "        print(\"Finished epoch {}, time elapsed {} seconds\".format(epoch, int(time.time() - ts)))\n",
    "\n",
    "        current_iou_score, current_val_loss = val(epoch)\n",
    "        val_loss.append(current_val_loss)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if epoch == 0 or current_iou_score < best_iou_score:\n",
    "            best_iou_score = current_iou_score\n",
    "            patience = 0\n",
    "            best_model = copy.deepcopy(fcn_model)\n",
    "        else:\n",
    "            if early_stop:\n",
    "                patience += 1\n",
    "                if patience >= early_stop_epoch:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "    \n",
    "\n",
    "    plot_losses(training_loss, val_loss, early_stop=epoch if early_stop and patience >= early_stop_epoch else None)\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def val(epoch=-1):\n",
    "    \"\"\"\n",
    "    Validate the deep learning model on a validation dataset.\n",
    "\n",
    "    - Set model to evaluation mode.\n",
    "    - Disable gradient calculations.\n",
    "    - Iterate over validation data loader:\n",
    "        - Perform forward pass to get outputs.\n",
    "        - Compute loss and accumulate it.\n",
    "        - Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the epoch.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean IoU score and mean loss for this validation epoch.\n",
    "    \"\"\"\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        for iter, (inputs, labels) in enumerate(val_loader):\n",
    "\n",
    "            inputs =  inputs.to(device)\n",
    "            labels =  labels.to(device)\n",
    "            \n",
    "            outputs = fcn_model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels.long())\n",
    "            losses.append(loss.cpu().item())\n",
    "\n",
    "            iou_score = iou(outputs, labels)\n",
    "            mean_iou_scores.append(iou_score.cpu().item())\n",
    "\n",
    "            acc = pixel_acc(outputs, labels)\n",
    "            accuracy.append(acc.cpu().item())\n",
    "\n",
    "    if epoch != -1:\n",
    "        print(f\"Loss at epoch {epoch}: {np.mean(losses)}\")\n",
    "        print(f\"IoU at epoch {epoch}: {np.mean(mean_iou_scores)}\")\n",
    "        print(f\"Pixel Accuracy at epoch {epoch}: {np.mean(accuracy)}\")\n",
    "    else:\n",
    "        print(f\"Initial Loss: {np.mean(losses)}\")\n",
    "        print(f\"Initial IoU {np.mean(mean_iou_scores)}\")\n",
    "        print(f\"Initial Pixel Accuracy {np.mean(accuracy)}\")\n",
    "\n",
    "    fcn_model.train() #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n",
    "    return np.mean(mean_iou_scores), np.mean(losses)\n",
    "\n",
    "\n",
    "def modelTest(fcn_model):\n",
    "    \"\"\"\n",
    "    Test the deep learning model using a test dataset.\n",
    "\n",
    "    - Load the model with the best weights.\n",
    "    - Set the model to evaluation mode.\n",
    "    - Iterate over the test data loader:\n",
    "        - Perform forward pass and compute loss.\n",
    "        - Accumulate loss, IoU scores, and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the test data.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Returns:\n",
    "        None. Outputs average test metrics to the console.\n",
    "    \"\"\"\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        for iter, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "            inputs =  inputs.to(device)\n",
    "            labels =  labels.to(device)\n",
    "            \n",
    "            outputs = fcn_model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels.long())\n",
    "            losses.append(loss.cpu().item())\n",
    "\n",
    "            iou_score = iou(outputs, labels)\n",
    "            mean_iou_scores.append(iou_score.cpu().item())\n",
    "\n",
    "            acc = pixel_acc(outputs, labels)\n",
    "            accuracy.append(acc.cpu().item())\n",
    "\n",
    "\n",
    "    print(f\"Test Loss: {np.mean(losses)}\")\n",
    "    print(f\"Test IoU: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Test Pixel acc: {np.mean(accuracy)}\")\n",
    "\n",
    "    fcn_model.train() #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n",
    "    return np.mean(mean_iou_scores)\n",
    "\n",
    "\n",
    "def exportModel(inputs):    \n",
    "    \"\"\"\n",
    "    Export the output of the model for given inputs.\n",
    "\n",
    "    - Set the model to evaluation mode.\n",
    "    - Load the model with the best saved weights.\n",
    "    - Perform a forward pass with the model to get output.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        inputs: Input data to the model.\n",
    "\n",
    "    Returns:\n",
    "        Output from the model for the given inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    saved_model_path = \"Fill Path To Best Model\"\n",
    "    # TODO Then Load your best model using saved_model_path\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output_image = fcn_model(inputs)\n",
    "    \n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Accuracy before training: \")\n",
    "    val()  # show the accuracy before training\n",
    "    print(\"\\n Starting training.\")\n",
    "    model = train()\n",
    "    modelTest(model)\n",
    "    \n",
    "    \n",
    "\n",
    "    # housekeeping\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1694054-aa4f-479f-9101-8817b3b6c2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
